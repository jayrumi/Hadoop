Реализуйте reducer первой mapreduce задачи для расчета TF-IDF с помощью Hadoop Streaming.

Ключ входных данных составной: он содержит слово и номер документа через "#".

Ключом в выходных данных является слово, а значение состоит из двух элементов, разделенных табуляцией: 
номер документа и tf (сколько раз данное слово встретилось в данном документе).

Sample Input:
  aut#1	1
  aut#1	1
  aut#1	1
  aut#1	1
  aut#2	1
  aut#2	1
  bene#2	1
  de#2	1
  mortuis#2	1
  nihil#1	1
  nihil#2	1
  Caesar#1	1

Sample Output:
  aut	1	4
  aut	2	2
  bene	2	1
  de	2	1
  mortuis	2	1
  nihil	1	1
  nihil	2	1
  Caesar	1	1


# python3
import sys
import re

arr = []

# input comes from STDIN
for token in sys.stdin:
	retoken = re.findall(r"[\w']+", token.strip())
	word, doc, j = retoken
	wd = str(word)+' '+str(doc)
	arr.append(wd)

#print(arr)
dct2 = {}

for i in arr:
	dct2.update({i:arr.count(i)})
for d in dct2:
	wrd, doc = d.split()
	print(str(wrd)+ str("\t") + str(doc) + str("\t") + str(dct2[d]))
