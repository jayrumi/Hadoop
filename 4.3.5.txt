Реализуйте reducer второй mapreduce задачи для расчета TF-IDF с помощью Hadoop Streaming.

Входные данные: ключ - слово, значение - тройка: номер документа, tf слова в документе и 1 (разделены ';').

Выходные данные: ключ - пара: слово, номер документа (разделены '#'), значение - пара: tf слова в документе, 
n - количество документов с данным словом (разделены табуляцией).

Sample Input:
  aut	1;4;1
  aut	2;2;1
  bene	2;1;1
  de	2;1;1
  mortuis	2;1;1
  nihil	1;1;1
  nihil	2;1;1
  Caesar	1;1;1

Sample Output:
  aut#1	4	2
  aut#2	2	2
  bene#2	1	1
  de#2	1	1
  mortuis#2	1	1
  nihil#1	1	2
  nihil#2	1	2
  Caesar#1	1	1


# python3
import sys
import re

arrWord = []
arrMetrics = []
# input comes from STDIN
for token in sys.stdin:
	retoken = re.findall(r"[\w']+", token.strip())
	word, doc, cnt, ones = retoken
	arrWord.append(word)
	arrMetrics.append(word + ' ' + doc + ' ' + cnt)

dct = {}

for i in arrWord:
	dct.update({i:arrWord.count(i)})

for wrd in dct:
	for val in arrMetrics:
		word, doc, cnt = val.split()
		if wrd == word:
			print('%s#%s\t%s\t%s' % (word, doc, cnt, dct[wrd]))
	
